{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kLdTjjkkpH7"
   },
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17071,
     "status": "ok",
     "timestamp": 1744348614963,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "PxjGiug1DmSI",
    "outputId": "5827db2a-dc89-4757-f202-3a7c54356d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/gdrive')\n",
    "os.chdir(\"/content/gdrive/Othercomputers/retep's PC/MambaVAE\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13762,
     "status": "ok",
     "timestamp": 1744348628741,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "x0z1C7SdkxDw",
    "outputId": "ea65299f-d554-43cb-b3ce-afcabeb63bac"
   },
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135313,
     "status": "ok",
     "timestamp": 1744348764051,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "z352JAzlidGI",
    "outputId": "f6e143d7-51df-48a6-8fef-3404da8e3c80"
   },
   "outputs": [],
   "source": [
    "%pip install causal_conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHi4PtdekpIU"
   },
   "source": [
    "# vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsqZr9NKCXjh"
   },
   "outputs": [],
   "source": [
    "import torch, InitMamba, importlib\n",
    "from datasets import load_from_disk\n",
    "importlib.reload(InitMamba)\n",
    "import VAE\n",
    "importlib.reload(VAE)\n",
    "from VAE import MambaVAE\n",
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
    "from data.Dataset import get_dataset, tokenizer\n",
    "\n",
    "vae = MambaVAE().cuda().eval()\n",
    "vae.load_state_dict(torch.load('./results/vae/model.pth', weights_only=True), strict=False)\n",
    "\n",
    "dataset = load_from_disk(\"./data/CoT3\")\n",
    "# train_dataset, eval_dataset = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDzg-k7EBx9k"
   },
   "outputs": [],
   "source": [
    "id = 1\n",
    "question_ids = torch.tensor([dataset[id]['question_ids']], device='cuda')\n",
    "question_mask = torch.tensor([dataset[id]['question_mask']], device='cuda')\n",
    "full_ids = torch.tensor([dataset[id]['full_ids']], device='cuda')\n",
    "full_mask = torch.tensor([dataset[id]['full_mask']], device='cuda')\n",
    "full_loss_mask = torch.tensor([dataset[id]['full_loss_mask']], device='cuda')\n",
    "tokenizer.batch_decode(full_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJF75eZseUIO"
   },
   "outputs": [],
   "source": [
    "# input_ids, mask = question_ids, question_mask\n",
    "# input_ids, mask = thoughts_ids, thoughts_mask\n",
    "vae.eval()\n",
    "state, log_var = vae.encode(full_ids, full_mask)\n",
    "\n",
    "# idx = (state.abs() > 3)\n",
    "# print(idx.sum() / state.numel())\n",
    "# mix_state = state.clone()\n",
    "# mix_state[idx] = torch.randn_like(state[idx])\n",
    "\n",
    "res = vae.decode(state, full_ids, full_mask, full_loss_mask)\n",
    "print(res.loss)\n",
    "tokenizer.batch_decode(res.logits.argmax(-1), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBeiZxlPORlI"
   },
   "outputs": [],
   "source": [
    "r = 0.2\n",
    "noise = torch.randn_like(state)\n",
    "mix_state = (state*r**0.5+noise*(1-r)**0.5)\n",
    "\n",
    "# idx = (state.abs() < 0.1)\n",
    "# print(idx.sum() / state.numel())\n",
    "# mix_state[idx] = torch.randn_like(state[idx]) * 0\n",
    "vae.eval()\n",
    "empty_ids = tokenizer('<|startoftext|>', return_tensors='pt').to('cuda')\n",
    "tokens = vae.decoder.generate(input_ids = question_ids[:,:question_mask.sum()],\n",
    "                inputs_ssm_states = vae.mlp2(mix_state),\n",
    "                inputs_ssm_layer = 11,\n",
    "                max_length = 256,\n",
    "                # num_beams = 10\n",
    "                )\n",
    "tokenizer.batch_decode(tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hsDaG4LrMWk"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vae.train()\n",
    "data_np = states.flatten().detach().cpu().numpy()\n",
    "plt.hist(data_np, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBc4yK6aElre"
   },
   "outputs": [],
   "source": [
    "vae.sample(state, log_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE38H9XWSAT1"
   },
   "source": [
    "# baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VTScFw6jwCE"
   },
   "outputs": [],
   "source": [
    "import torch, transformers, os\n",
    "from transformers import TrainingArguments, AutoTokenizer\n",
    "from InitMamba import MambaForCausalLM\n",
    "from datasets import load_dataset\n",
    "import dataset.Dataset as Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "model = MambaForCausalLM.from_pretrained('state-spaces/mamba-130m-hf').cuda()\n",
    "dataset = load_dataset(\"arrow\", data_files = './cache/CoT_full.arrow', split = 'train').select(range(100000))\n",
    "print(dataset)\n",
    "tot = len(dataset)\n",
    "eval_size= int(tot * 0.05)\n",
    "train_dataset = dataset.select(range(eval_size, tot))\n",
    "eval_dataset = dataset.select(range(eval_size))\n",
    "model.load_state_dict(torch.load(\"results/CoT_full/model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_ZcCjHXY8Lu"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "input_str = tokenizer.decode(eval_dataset[1]['input_ids'], skip_special_tokens=True)\n",
    "input_ids = tokenizer(input_str.split(' Thinking: ')[0] + ' Thinking: ', return_tensors = 'pt')['input_ids'].cuda()\n",
    "tokens = model.generate(\n",
    "    input_ids,\n",
    "    max_length = 512,\n",
    "    # num_return_sequences = 5,\n",
    "    # do_sample = False,\n",
    "    # num_beams = 5\n",
    "    )\n",
    "print(input_str)\n",
    "tokenizer.batch_decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oCPXeJZunmm"
   },
   "source": [
    "# diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2710,
     "status": "ok",
     "timestamp": 1744350205242,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "eXnqjD9dre1C",
    "outputId": "b8724178-fb39-47fa-f151-6a0d05c1772b"
   },
   "outputs": [],
   "source": [
    "import importlib, torch\n",
    "from datasets import load_from_disk\n",
    "from VAE import MambaVAE\n",
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer\n",
    "\n",
    "dataset = load_from_disk(\"./data/CoT3\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "tokenizer.add_tokens([\"<|startoftext|>\", \"<|thoughts|>\", \"<|answer|>\"])\n",
    "\n",
    "vae = MambaVAE().cuda().eval()\n",
    "vae.load_state_dict(torch.load('./results/vae0.2/model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1744350208257,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "TmyDvOLUGpYx",
    "outputId": "917a7ef9-19f9-4e88-a5c9-502159242a13"
   },
   "outputs": [],
   "source": [
    "import Diffuser, importlib, torch\n",
    "importlib.reload(Diffuser)\n",
    "from Diffuser import Diffuser\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "diff = Diffuser().cuda().eval()\n",
    "diff.load_state_dict(load_file('results/diff46'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1744350285148,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "eFXQ4jEcsMuQ",
    "outputId": "7e50e62e-9e58-4bca-f7eb-ec50bf81f131"
   },
   "outputs": [],
   "source": [
    "id = 1\n",
    "question_ids = torch.tensor([dataset[id]['question_ids']], device='cuda')\n",
    "question_mask = torch.tensor([dataset[id]['question_mask']], device='cuda')\n",
    "full_ids = torch.tensor([dataset[id]['full_ids']], device='cuda')\n",
    "full_mask = torch.tensor([dataset[id]['full_mask']], device='cuda')\n",
    "full_loss_mask = torch.tensor([dataset[id]['full_loss_mask']], device='cuda')\n",
    "\n",
    "target = vae.encode(full_ids, full_mask)[0].clamp(-1, 1)\n",
    "condition = vae.encode(question_ids, question_mask)[0].clamp(-1, 1)\n",
    "\n",
    "tokenizer.batch_decode(full_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1744350281475,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "SyPbwva2XY3Y",
    "outputId": "367f4294-ba6c-4694-bc92-dd14f3fdf04d"
   },
   "outputs": [],
   "source": [
    "res = diff(target = target, condition = condition)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1744349266979,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "HnrwqM_QsEsU",
    "outputId": "053f56b0-69b0-4d2e-e261-2aaf139665b7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(target.unsqueeze(-1).reshape(64, 64).detach().cpu())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1744350289733,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "ZeGWRHNriAOi",
    "outputId": "4b89fbf4-e533-42c0-8862-6e934c9b2dda"
   },
   "outputs": [],
   "source": [
    "# states = diff.generate(condition, 1000)\n",
    "print((states - target).pow(2).mean())\n",
    "vae.decode(states, full_ids, full_mask, full_loss_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1744350293687,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 300
    },
    "id": "uMoI7iNKtErw",
    "outputId": "e2ebd0a0-1f67-4401-d7a9-48dc4ba5d2cc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(states.reshape(64, 64).detach().cpu())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_w2axzDutMC"
   },
   "outputs": [],
   "source": [
    "r = 0\n",
    "tokens = vae.decoder.generate(input_ids = question_ids[:,:question_mask.sum()],\n",
    "                inputs_ssm_states = vae.mlp2(torch.randn_like(states)*r**0.5 + states*(1-r)**0.5),\n",
    "                inputs_ssm_layer = 11,\n",
    "                max_length = 256,\n",
    "                # do_sample=True,\n",
    "                # num_return_sequences=3\n",
    "                )\n",
    "tokenizer.batch_decode(tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsx3x4IA0AnB"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI65tdkpLD3B"
   },
   "outputs": [],
   "source": [
    "!python data/Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZsq3PdNkpIX"
   },
   "outputs": [],
   "source": [
    "!python VAE_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BWvknpyjuQc"
   },
   "outputs": [],
   "source": [
    "!python Baseline_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "6V6X1eTSMNLE"
   },
   "outputs": [],
   "source": [
    "!python Diffuser_trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZD55Rw9XCjDE"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "_kLdTjjkkpH7",
    "TE38H9XWSAT1",
    "1oCPXeJZunmm"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
