{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kLdTjjkkpH7"
   },
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3100,
     "status": "ok",
     "timestamp": 1738709102558,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 360
    },
    "id": "PxjGiug1DmSI",
    "outputId": "b1894dff-14cc-4c5c-e74e-3e5c41f9ee32"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/gdrive')\n",
    "os.chdir(\"/content/gdrive/Othercomputers/retep's PC/MambaVAE\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81846,
     "status": "ok",
     "timestamp": 1738709184401,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 360
    },
    "id": "x0z1C7SdkxDw",
    "outputId": "11bd4808-69a1-4e29-e9e0-ac50720d7ccf"
   },
   "outputs": [],
   "source": [
    "%pip install datasets causal_conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHi4PtdekpIU"
   },
   "source": [
    "# Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orX7-rvKAG4Y"
   },
   "outputs": [],
   "source": [
    "import VAE, importlib\n",
    "importlib.reload(VAE)\n",
    "from VAE import MambaVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsqZr9NKCXjh"
   },
   "outputs": [],
   "source": [
    "import torch, InitMamba, importlib\n",
    "importlib.reload(InitMamba)\n",
    "from transformers import MambaConfig, MambaForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "3NTBfcLqCZUm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS token ID: 50277\n",
      "EOS token ID: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "tokenizer.add_special_tokens({\"bos_token\": \"<|startoftext|>\"})\n",
    "print(\"BOS token ID:\", tokenizer.bos_token_id)\n",
    "print(\"EOS token ID:\", tokenizer.eos_token_id)\n",
    "inputs = tokenizer([\"<|startoftext|>Today is sunny. I'm happy.<|endoftext|>\", \"<|startoftext|>Today is sunny. I'm happy.<|endoftext|>\"], return_tensors='pt') #.to('cuda')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0, 21366,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "          3615,     0],\n",
       "        [    0,     0,     0,     0,     0, 14497,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0, 45248,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer([\"<|endoftext|>\", \"<|endoftext|>\"], return_tensors='pt', max_length=32, padding='max_length')\n",
    "\n",
    "def add_rand_token(input_ids):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        pos = (torch.rand(2, batch_size, device=input_ids.device) * 32).long()\n",
    "        rand_token = (torch.rand(2, batch_size, device=input_ids.device) * 50276 + 1).long()\n",
    "        new_input_ids = input_ids\n",
    "        new_input_ids[torch.arange(batch_size),pos] = rand_token\n",
    "        return new_input_ids\n",
    "add_rand_token(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VscTnFtgx5Zl"
   },
   "outputs": [],
   "source": [
    "vae = MambaVAE().cuda()\n",
    "vae.load_state_dict(torch.load('./results/result5/model.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJF75eZseUIO"
   },
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "res = vae(**inputs)\n",
    "tokenizer.batch_decode(res[2].argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-Rb155MyPuz"
   },
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "state = vae.encode(**inputs)\n",
    "res = vae.decode(state, **inputs)\n",
    "tokenizer.batch_decode(res.logits.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4er9fU7PdFRH"
   },
   "outputs": [],
   "source": [
    "inputs2 = tokenizer([\"\\n\"], return_tensors='pt').to('cuda')\n",
    "state2 = vae.encode(**inputs2)\n",
    "res = vae.decode(state, **inputs2)\n",
    "tokenizer.batch_decode(res.logits.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMm-kReNIKgy"
   },
   "outputs": [],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jF_SFl1TCiLw"
   },
   "outputs": [],
   "source": [
    "model1 = InitMamba.MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\").cuda()\n",
    "model2 = InitMamba.MambaModel.from_pretrained(\"state-spaces/mamba-130m-hf\").cuda()\n",
    "# model1.train()\n",
    "# model2.train()\n",
    "\n",
    "# hidden_states = model2(**inputs, layer_range = range(23))[0]\n",
    "# res1 = model1(inputs_embeds = hidden_states, attention_mask = inputs['attention_mask'], layer_range = range(23, 24), output_ssm_last_states = True)\n",
    "res1 = model1(**inputs, labels = inputs['input_ids'], output_ssm_last_states = True)\n",
    "# ssm_last_states = res1.ssm_last_states\n",
    "# print(res1[0])\n",
    "print((res1.ssm_last_states).pow(2).sum()/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qII4_vKLI75O"
   },
   "outputs": [],
   "source": [
    "res1.ssm_last_states.abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWoYm4XCCyk9"
   },
   "outputs": [],
   "source": [
    "hidden_states = model2(**inputs, layer_range = range(1), inputs_ssm_states = ssm_last_states)[0]\n",
    "res1 = model1(inputs_embeds = hidden_states, attention_mask = inputs['attention_mask'],\n",
    "              layer_range = range(1, 24),\n",
    "              output_ssm_last_states = True,\n",
    "              inputs_ssm_states = ssm_last_states)\n",
    "res = model1(**inputs,\n",
    "             output_ssm_last_states = True,\n",
    "             inputs_ssm_states = ssm_last_states)\n",
    "print(res.logits-res1.logits)\n",
    "print(res.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xsx3x4IA0AnB"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14988,
     "status": "ok",
     "timestamp": 1738723483721,
     "user": {
      "displayName": "EN WEI",
      "userId": "03929691894706464420"
     },
     "user_tz": 360
    },
    "id": "rZsq3PdNkpIX",
    "outputId": "2e385929-a449-49bf-944d-7c3e4022159a"
   },
   "outputs": [],
   "source": [
    "!python Trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLobtlCAz-hd"
   },
   "outputs": [],
   "source": [
    "!python Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZD55Rw9XCjDE"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "_kLdTjjkkpH7"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
